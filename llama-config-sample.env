# Llama Configuration for Script Refinement
# Add these to your .env.local file to enable Llama integration

# URL to your Llama server (default for LM Studio and many other implementations)
LLAMA_API_BASE=http://localhost:8080/v1

# Model name as configured in your Llama server
# Common values: llama2, llama3, mistral, etc.
LLAMA_MODEL_NAME=llama2

# API key (many local Llama servers don't check this, but the field is required)
LLAMA_API_KEY=sk-no-key-required 